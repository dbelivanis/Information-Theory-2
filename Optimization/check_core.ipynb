{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.1",
   "language": "julia"
  },
  "metadata": {
   "interpreter": {
    "hash": "4b52351028b39e813c82a08b1f92f8b08c926f93d8b7c782ac06736618b2486c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-30 19:53:49.424382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\nWARNING: using param.param in module aux_functions conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "include(\"./param.jl\");\n",
    "include(\"./aux_functions.jl\");\n",
    "\n",
    "using Main.aux_functions\n",
    "using Main.param\n",
    "using ADCME\n",
    "using SparseArrays\n",
    "\n",
    "using DelimitedFiles\n",
    "using Dates\n",
    "using Plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "maxiter = 10\n",
    "N_steps = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "maximum iteration: 10\tNumber of steps: 3\n",
      "2.830469177224561e-5C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "2021-05-30 19:55:18.143792: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "2021-05-30 19:55:18.156606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\n",
      "2021-05-30 19:55:18.218162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1650 major: 7 minor: 5 memoryClockRate(GHz): 1.56\n",
      "pciBusID: 0000:01:00.0\n",
      "2021-05-30 19:55:18.218658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n",
      "2021-05-30 19:55:18.271150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\n",
      "2021-05-30 19:55:18.544395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll\n",
      "2021-05-30 19:55:18.559145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll\n",
      "2021-05-30 19:55:18.633482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll\n",
      "2021-05-30 19:55:18.916929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll\n",
      "2021-05-30 19:55:19.062165: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\n",
      "2021-05-30 19:55:19.063154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-05-30 19:55:23.297373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-05-30 19:55:23.297413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-05-30 19:55:23.297425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-05-30 19:55:23.301596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2919 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print(\"maximum iteration: \",maxiter,\"\\t\",\"Number of steps: \",N_steps,\"\\n\")\n",
    "param_model_val = param_model(N_steps=N_steps);\n",
    "tf_variables, h_t, q_t_x, q_t_y = Darcy_flow_solver(param_model_val);\n",
    "\n",
    "loss,dw_2, opt_ADAM, opt_LFGS, opt_ADAM_sum, opt_LFGS_sum, diff_eval,p_pre_soft_max, p = Info_upscale(tf_variables,param_model_val,q_t_x, q_t_y,maxiter)\n",
    "\n",
    "sess = Session(); init(sess);\n",
    "\n",
    "\n",
    "global N_k_dis_ = 4\n",
    "global T_exp = -2\n",
    "T_=  10.0 .^ -T_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19:55-2\t100.0\t0.0007267508285325198\t5.5210782319984135\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=0.0008692784609354104\n",
      "iter 1, current loss=0.0007249955080323163\n",
      "================ STEP 0 ===============\n",
      "iter 2, current loss=0.0002814875674504895\n",
      "================ STEP 1 ===============\n",
      "iter 3, current loss=0.00014080786291257642\n",
      "================ STEP 2 ===============\n",
      "iter 4, current loss=5.908145140680884e-5\n",
      "================ STEP 3 ===============\n",
      "iter 5, current loss=2.5844710307020072e-5\n",
      "================ STEP 4 ===============\n",
      "iter 6, current loss=1.2100804233498268e-5\n",
      "================ STEP 5 ===============\n",
      "iter 7, current loss=7.335628524489099e-6\n",
      "================ STEP 6 ===============\n",
      "iter 8, current loss=5.946421615631236e-6\n",
      "================ STEP 7 ===============\n",
      "iter 9, current loss=5.633951139083768e-6\n",
      "================ STEP 8 ===============\n",
      "iter 10, current loss=5.5777406334632155e-6\n",
      "================ STEP 9 ===============\n",
      "19:56-2\t100.0\t3.70757690127924e-5\t0.21644049768110213\t\t4\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.70757690127924e-5"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "\n",
    "# save_values(sess,param_model_val,tf_variables,q_t_x, q_t_y,p,\"w\")\n",
    "\n",
    "print_status(sess,loss,diff_eval,T_exp,T_,N_k_dis_,tf_variables)\n",
    "# ScipyOptimizerMinimize(sess, opt_LFGS_sum,feed_dict = Dict(tf_variables.lambda => ones(1)*T_,tf_variables.N_k_dis=>8))\n",
    "BFGS!(sess,dw_2*1e5,options=Dict(\"maxiter\"=> maxiter, \"ftol\"=>1e-12, \"gtol\"=>1e-12))\n",
    "\n",
    "# save_values(sess,param_model_val,tf_variables,q_t_x, q_t_y,p,\"a\")\n",
    "print_status(sess,loss,diff_eval,T_exp,T_,N_k_dis_,tf_variables)\n",
    "\n",
    "check_diff = run(sess,diff_eval,feed_dict = Dict(tf_variables.lambda => ones(1)*T_,tf_variables.N_k_dis=>N_k_dis_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19:56-2\t100.0\t3.70757690127924e-5\t0.21644049768110213\t\t4\n",
      "19:56-2\t100.0\t3.70757690127924e-5\t0.21644049768110213\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=21644.049768088513\n",
      "iter 1, current loss=11691.525324682636\n",
      "================ STEP 0 ===============\n",
      "iter 2, current loss=8105.697529602203\n",
      "================ STEP 1 ===============\n",
      "iter 3, current loss=7533.509126692936\n",
      "================ STEP 2 ===============\n",
      "iter 4, current loss=7190.783788108559\n",
      "================ STEP 3 ===============\n",
      "iter 5, current loss=6942.582274202099\n",
      "================ STEP 4 ===============\n",
      "iter 6, current loss=6447.126407047822\n",
      "================ STEP 5 ===============\n",
      "iter 7, current loss=6224.470870464529\n",
      "================ STEP 6 ===============\n",
      "iter 8, current loss=6050.866042373413\n",
      "================ STEP 7 ===============\n",
      "iter 9, current loss=6029.348154328089\n",
      "================ STEP 8 ===============\n",
      "iter 10, current loss=5994.1514087052565\n",
      "================ STEP 9 ===============\n",
      "iter 11, current loss=5986.3683812725285\n",
      "================ STEP 10 ===============\n",
      "iter 12, current loss=5981.173504875239\n",
      "================ STEP 11 ===============\n",
      "iter 13, current loss=5975.820796604028\n",
      "================ STEP 12 ===============\n",
      "iter 14, current loss=5974.014083245118\n",
      "================ STEP 13 ===============\n",
      "iter 15, current loss=5972.357472820461\n",
      "================ STEP 14 ===============\n",
      "iter 16, current loss=5970.144757840187\n",
      "================ STEP 15 ===============\n",
      "iter 17, current loss=5966.263579892454\n",
      "================ STEP 16 ===============\n",
      "iter 18, current loss=5961.463805819839\n",
      "================ STEP 17 ===============\n",
      "iter 19, current loss=5957.68006272351\n",
      "================ STEP 18 ===============\n",
      "iter 20, current loss=5955.636999999631\n",
      "================ STEP 19 ===============\n",
      "iter 21, current loss=5954.741944860272\n",
      "================ STEP 20 ===============\n",
      "iter 22, current loss=5954.292971670997\n",
      "================ STEP 21 ===============\n",
      "iter 23, current loss=5953.412702268409\n",
      "================ STEP 22 ===============\n",
      "iter 24, current loss=5954.088719166374\n",
      "iter 25, current loss=5953.215637329885\n",
      "================ STEP 23 ===============\n",
      "iter 26, current loss=5952.888674825874\n",
      "================ STEP 24 ===============\n",
      "iter 27, current loss=5952.677122939755\n",
      "================ STEP 25 ===============\n",
      "iter 28, current loss=5952.409965773891\n",
      "================ STEP 26 ===============\n",
      "iter 29, current loss=5952.324356801121\n",
      "================ STEP 27 ===============\n",
      "iter 30, current loss=5952.223299075293\n",
      "================ STEP 28 ===============\n",
      "iter 31, current loss=5952.1651231267615\n",
      "================ STEP 29 ===============\n",
      "iter 32, current loss=5952.081355016782\n",
      "================ STEP 30 ===============\n",
      "iter 33, current loss=5951.970304738453\n",
      "================ STEP 31 ===============\n",
      "iter 34, current loss=5952.035511104501\n",
      "iter 35, current loss=5951.898179809346\n",
      "================ STEP 32 ===============\n",
      "iter 36, current loss=5951.817227025588\n",
      "================ STEP 33 ===============\n",
      "iter 37, current loss=5951.749729608336\n",
      "================ STEP 34 ===============\n",
      "iter 38, current loss=5951.708007130085\n",
      "================ STEP 35 ===============\n",
      "iter 39, current loss=5951.693573373934\n",
      "================ STEP 36 ===============\n",
      "iter 40, current loss=5951.620208254603\n",
      "================ STEP 37 ===============\n",
      "iter 41, current loss=5951.607204286748\n",
      "================ STEP 38 ===============\n",
      "iter 42, current loss=5951.58640222995\n",
      "================ STEP 39 ===============\n",
      "iter 43, current loss=5951.555161921515\n",
      "================ STEP 40 ===============\n",
      "iter 44, current loss=5951.524347115882\n",
      "================ STEP 41 ===============\n",
      "iter 45, current loss=5951.514910591307\n",
      "================ STEP 42 ===============\n",
      "iter 46, current loss=5951.503461738645\n",
      "================ STEP 43 ===============\n",
      "iter 47, current loss=5951.500717388151\n",
      "================ STEP 44 ===============\n",
      "iter 48, current loss=5951.496975544995\n",
      "================ STEP 45 ===============\n",
      "iter 49, current loss=5951.490589890794\n",
      "================ STEP 46 ===============\n",
      "iter 50, current loss=5951.484444547657\n",
      "================ STEP 47 ===============\n",
      "iter 51, current loss=5951.479187393824\n",
      "================ STEP 48 ===============\n",
      "iter 52, current loss=5951.471600643247\n",
      "================ STEP 49 ===============\n",
      "iter 53, current loss=5951.474095796742\n",
      "iter 54, current loss=5951.46674382063\n",
      "================ STEP 50 ===============\n",
      "iter 55, current loss=5951.461935736957\n",
      "================ STEP 51 ===============\n",
      "iter 56, current loss=5951.458558034538\n",
      "================ STEP 52 ===============\n",
      "iter 57, current loss=5951.4537353168935\n",
      "================ STEP 53 ===============\n",
      "iter 58, current loss=5951.443225588081\n",
      "================ STEP 54 ===============\n",
      "iter 59, current loss=5951.427412541515\n",
      "================ STEP 55 ===============\n",
      "iter 60, current loss=5951.41268204409\n",
      "================ STEP 56 ===============\n",
      "iter 61, current loss=5951.404375502994\n",
      "================ STEP 57 ===============\n",
      "iter 62, current loss=5951.407702594817\n",
      "iter 63, current loss=5951.401673606679\n",
      "================ STEP 58 ===============\n",
      "iter 64, current loss=5951.39972994751\n",
      "================ STEP 59 ===============\n",
      "iter 65, current loss=5951.398100279725\n",
      "================ STEP 60 ===============\n",
      "iter 66, current loss=5951.395433719377\n",
      "================ STEP 61 ===============\n",
      "iter 67, current loss=5951.39325531879\n",
      "================ STEP 62 ===============\n",
      "iter 68, current loss=5951.390519877377\n",
      "================ STEP 63 ===============\n",
      "iter 69, current loss=5951.388664454019\n",
      "================ STEP 64 ===============\n",
      "iter 70, current loss=5951.386629489788\n",
      "================ STEP 65 ===============\n",
      "iter 71, current loss=5951.384483055047\n",
      "================ STEP 66 ===============\n",
      "iter 72, current loss=5951.382681295163\n",
      "================ STEP 67 ===============\n",
      "iter 73, current loss=5951.382309901473\n",
      "================ STEP 68 ===============\n",
      "iter 74, current loss=5951.38145855199\n",
      "================ STEP 69 ===============\n",
      "iter 75, current loss=5951.381113145166\n",
      "================ STEP 70 ===============\n",
      "iter 76, current loss=5951.380660009834\n",
      "================ STEP 71 ===============\n",
      "iter 77, current loss=5951.380278035881\n",
      "================ STEP 72 ===============\n",
      "iter 78, current loss=5951.380078955541\n",
      "================ STEP 73 ===============\n",
      "iter 79, current loss=5951.37978076776\n",
      "================ STEP 74 ===============\n",
      "iter 80, current loss=5951.379712703412\n",
      "================ STEP 75 ===============\n",
      "iter 81, current loss=5951.379282237071\n",
      "================ STEP 76 ===============\n",
      "iter 82, current loss=5951.379184863362\n",
      "================ STEP 77 ===============\n",
      "iter 83, current loss=5951.379016445868\n",
      "================ STEP 78 ===============\n",
      "iter 84, current loss=5951.378806181952\n",
      "================ STEP 79 ===============\n",
      "iter 85, current loss=5951.378626156854\n",
      "================ STEP 80 ===============\n",
      "iter 86, current loss=5951.378417044259\n",
      "================ STEP 81 ===============\n",
      "iter 87, current loss=5951.378176589332\n",
      "================ STEP 82 ===============\n",
      "iter 88, current loss=5951.377890990395\n",
      "================ STEP 83 ===============\n",
      "iter 89, current loss=5951.37755296151\n",
      "================ STEP 84 ===============\n",
      "iter 90, current loss=5951.377374195319\n",
      "================ STEP 85 ===============\n",
      "iter 91, current loss=5951.377113400065\n",
      "================ STEP 86 ===============\n",
      "iter 92, current loss=5951.376755827367\n",
      "================ STEP 87 ===============\n",
      "iter 93, current loss=5951.376414632492\n",
      "================ STEP 88 ===============\n",
      "iter 94, current loss=5951.376044512319\n",
      "================ STEP 89 ===============\n",
      "iter 95, current loss=5951.375897009491\n",
      "================ STEP 90 ===============\n",
      "iter 96, current loss=5951.375661537451\n",
      "================ STEP 91 ===============\n",
      "iter 97, current loss=5951.375358244103\n",
      "================ STEP 92 ===============\n",
      "iter 98, current loss=5951.375259832343\n",
      "================ STEP 93 ===============\n",
      "iter 99, current loss=5951.375091817646\n",
      "================ STEP 94 ===============\n",
      "iter 100, current loss=5951.375021790875\n",
      "================ STEP 95 ===============\n",
      "iter 101, current loss=5951.374929876453\n",
      "================ STEP 96 ===============\n",
      "iter 102, current loss=5951.374821274398\n",
      "================ STEP 97 ===============\n",
      "iter 103, current loss=5951.374683526293\n",
      "================ STEP 98 ===============\n",
      "iter 104, current loss=5951.374630365908\n",
      "================ STEP 99 ===============\n",
      "19:56-2\t100.0\t9.831275556313549e-6\t0.05951374630365909\t\t4\n",
      "function for update K:9.831275556313549e-6\t4\n",
      "19:57-1.9\t79.43282347242814\t0.0007272787654112593\t0.0749237529618759\t\t4\n",
      "19:57-1.9\t79.43282347242814\t0.0007272787654112593\t0.0749237529618759\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=7492.375296176353\n",
      "iter 1, current loss=23207.389330335012\n",
      "iter 2, current loss=7514.090224814492\n",
      "iter 3, current loss=7492.355308272971\n",
      "================ STEP 0 ===============\n",
      "iter 4, current loss=7492.350270656862\n",
      "================ STEP 1 ===============\n",
      "iter 5, current loss=7492.341298767087\n",
      "================ STEP 2 ===============\n",
      "iter 6, current loss=7492.342792531188\n",
      "iter 7, current loss=7492.339805836977\n",
      "================ STEP 3 ===============\n",
      "iter 8, current loss=7492.339429414077\n",
      "================ STEP 4 ===============\n",
      "iter 9, current loss=7492.3383772021025\n",
      "================ STEP 5 ===============\n",
      "iter 10, current loss=7492.337729874761\n",
      "================ STEP 6 ===============\n",
      "iter 11, current loss=7492.337304149167\n",
      "================ STEP 7 ===============\n",
      "iter 12, current loss=7492.337148380174\n",
      "================ STEP 8 ===============\n",
      "iter 13, current loss=7492.33705087839\n",
      "================ STEP 9 ===============\n",
      "iter 14, current loss=7492.336993374041\n",
      "================ STEP 10 ===============\n",
      "iter 15, current loss=7492.3369207763935\n",
      "================ STEP 11 ===============\n",
      "iter 16, current loss=7492.337060913703\n",
      "iter 17, current loss=7492.33689982961\n",
      "================ STEP 12 ===============\n",
      "iter 18, current loss=7492.336867301372\n",
      "================ STEP 13 ===============\n",
      "iter 19, current loss=7492.336812173383\n",
      "================ STEP 14 ===============\n",
      "iter 20, current loss=7492.336771669816\n",
      "================ STEP 15 ===============\n",
      "iter 21, current loss=7492.336843954287\n",
      "iter 22, current loss=7492.33674517159\n",
      "================ STEP 16 ===============\n",
      "iter 23, current loss=7492.336684203204\n",
      "================ STEP 17 ===============\n",
      "iter 24, current loss=7492.336607666235\n",
      "================ STEP 18 ===============\n",
      "iter 25, current loss=7492.33651913865\n",
      "================ STEP 19 ===============\n",
      "iter 26, current loss=7492.336437863988\n",
      "================ STEP 20 ===============\n",
      "iter 27, current loss=7492.336361236541\n",
      "================ STEP 21 ===============\n",
      "iter 28, current loss=7492.3362918492485\n",
      "================ STEP 22 ===============\n",
      "iter 29, current loss=7492.336214204832\n",
      "================ STEP 23 ===============\n",
      "iter 30, current loss=7492.336260931118\n",
      "iter 31, current loss=7492.336193016696\n",
      "================ STEP 24 ===============\n",
      "iter 32, current loss=7492.336177106351\n",
      "================ STEP 25 ===============\n",
      "iter 33, current loss=7492.336155065515\n",
      "================ STEP 26 ===============\n",
      "iter 34, current loss=7492.336136247887\n",
      "================ STEP 27 ===============\n",
      "iter 35, current loss=7492.336115896612\n",
      "================ STEP 28 ===============\n",
      "iter 36, current loss=7492.336093200823\n",
      "================ STEP 29 ===============\n",
      "iter 37, current loss=7492.3360833165825\n",
      "================ STEP 30 ===============\n",
      "iter 38, current loss=7492.336074415496\n",
      "================ STEP 31 ===============\n",
      "iter 39, current loss=7492.336067846866\n",
      "================ STEP 32 ===============\n",
      "iter 40, current loss=7492.336051481768\n",
      "================ STEP 33 ===============\n",
      "iter 41, current loss=7492.336035659175\n",
      "================ STEP 34 ===============\n",
      "iter 42, current loss=7492.3360151731795\n",
      "================ STEP 35 ===============\n",
      "iter 43, current loss=7492.335993387691\n",
      "================ STEP 36 ===============\n",
      "iter 44, current loss=7492.335975377969\n",
      "================ STEP 37 ===============\n",
      "iter 45, current loss=7492.335953596034\n",
      "================ STEP 38 ===============\n",
      "iter 46, current loss=7492.335920380958\n",
      "================ STEP 39 ===============\n",
      "iter 47, current loss=7492.335882516697\n",
      "================ STEP 40 ===============\n",
      "iter 48, current loss=7492.335862646774\n",
      "================ STEP 41 ===============\n",
      "iter 49, current loss=7492.33584103588\n",
      "================ STEP 42 ===============\n",
      "iter 50, current loss=7492.335828305382\n",
      "================ STEP 43 ===============\n",
      "iter 51, current loss=7492.335800765018\n",
      "================ STEP 44 ===============\n",
      "iter 52, current loss=7492.335769027369\n",
      "================ STEP 45 ===============\n",
      "iter 53, current loss=7492.335754645658\n",
      "================ STEP 46 ===============\n",
      "iter 54, current loss=7492.335739500428\n",
      "================ STEP 47 ===============\n",
      "iter 55, current loss=7492.33573633689\n",
      "================ STEP 48 ===============\n",
      "iter 56, current loss=7492.335733748293\n",
      "================ STEP 49 ===============\n",
      "iter 57, current loss=7492.335730858314\n",
      "================ STEP 50 ===============\n",
      "iter 58, current loss=7492.3357298118235\n",
      "================ STEP 51 ===============\n",
      "iter 59, current loss=7492.33572813733\n",
      "================ STEP 52 ===============\n",
      "iter 60, current loss=7492.335728384277\n",
      "iter 61, current loss=7492.335727653866\n",
      "================ STEP 53 ===============\n",
      "iter 62, current loss=7492.335727045505\n",
      "================ STEP 54 ===============\n",
      "iter 63, current loss=7492.335726178003\n",
      "================ STEP 55 ===============\n",
      "iter 64, current loss=7492.3357253947015\n",
      "================ STEP 56 ===============\n",
      "iter 65, current loss=7492.335723515983\n",
      "================ STEP 57 ===============\n",
      "iter 66, current loss=7492.335721008569\n",
      "================ STEP 58 ===============\n",
      "iter 67, current loss=7492.335718019088\n",
      "================ STEP 59 ===============\n",
      "iter 68, current loss=7492.335714880605\n",
      "================ STEP 60 ===============\n",
      "iter 69, current loss=7492.335712700766\n",
      "================ STEP 61 ===============\n",
      "iter 70, current loss=7492.33571052321\n",
      "================ STEP 62 ===============\n",
      "iter 71, current loss=7492.335709182242\n",
      "================ STEP 63 ===============\n",
      "iter 72, current loss=7492.335706782763\n",
      "================ STEP 64 ===============\n",
      "iter 73, current loss=7492.335705181411\n",
      "================ STEP 65 ===============\n",
      "iter 74, current loss=7492.335707519022\n",
      "iter 75, current loss=7492.335704615127\n",
      "================ STEP 66 ===============\n",
      "iter 76, current loss=7492.335703957247\n",
      "================ STEP 67 ===============\n",
      "iter 77, current loss=7492.335703205478\n",
      "================ STEP 68 ===============\n",
      "iter 78, current loss=7492.335701617724\n",
      "================ STEP 69 ===============\n",
      "iter 79, current loss=7492.335700643831\n",
      "================ STEP 70 ===============\n",
      "iter 80, current loss=7492.335700661798\n",
      "iter 81, current loss=7492.335700279947\n",
      "================ STEP 71 ===============\n",
      "iter 82, current loss=7492.335700045302\n",
      "================ STEP 72 ===============\n",
      "iter 83, current loss=7492.335699919865\n",
      "================ STEP 73 ===============\n",
      "iter 84, current loss=7492.335699721214\n",
      "================ STEP 74 ===============\n",
      "iter 85, current loss=7492.335699436269\n",
      "================ STEP 75 ===============\n",
      "iter 86, current loss=7492.335699310772\n",
      "================ STEP 76 ===============\n",
      "iter 87, current loss=7492.3356991729\n",
      "================ STEP 77 ===============\n",
      "iter 88, current loss=7492.335699139442\n",
      "================ STEP 78 ===============\n",
      "iter 89, current loss=7492.335699091971\n",
      "================ STEP 79 ===============\n",
      "iter 90, current loss=7492.335699054447\n",
      "================ STEP 80 ===============\n",
      "iter 91, current loss=7492.335698979325\n",
      "================ STEP 81 ===============\n",
      "iter 92, current loss=7492.335698933352\n",
      "================ STEP 82 ===============\n",
      "iter 93, current loss=7492.33569891123\n",
      "================ STEP 83 ===============\n",
      "iter 94, current loss=7492.335698863673\n",
      "================ STEP 84 ===============\n",
      "iter 95, current loss=7492.335698716614\n",
      "================ STEP 85 ===============\n",
      "iter 96, current loss=7492.335700084073\n",
      "iter 97, current loss=7492.335698679083\n",
      "================ STEP 86 ===============\n",
      "iter 98, current loss=7492.335698582292\n",
      "================ STEP 87 ===============\n",
      "iter 99, current loss=7492.335698537316\n",
      "================ STEP 88 ===============\n",
      "iter 100, current loss=7492.3356984828115\n",
      "================ STEP 89 ===============\n",
      "iter 101, current loss=7492.335698429913\n",
      "================ STEP 90 ===============\n",
      "iter 102, current loss=7492.3356984259435\n",
      "iter 103, current loss=7492.335698384112\n",
      "================ STEP 91 ===============\n",
      "iter 104, current loss=7492.3356983533795\n",
      "================ STEP 92 ===============\n",
      "iter 105, current loss=7492.33569832788\n",
      "================ STEP 93 ===============\n",
      "iter 106, current loss=7492.335698323357\n",
      "================ STEP 94 ===============\n",
      "19:57-1.9\t79.43282347242814\t3.1047910445391203e-7\t0.07492335698324987\t\t4\n",
      "19:57-1.7999999999999998\t63.0957344480193\t3.1047910445391203e-7\t0.09432291804313797\t\t4\n",
      "19:57-1.7999999999999998\t63.0957344480193\t3.1047910445391203e-7\t0.09432291804313797\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=9432.291804311742\n",
      "iter 1, current loss=20647.705178312528\n",
      "iter 2, current loss=9432.291804291583\n",
      "================ STEP 0 ===============\n",
      "iter 3, current loss=9432.291804310158\n",
      "iter 4, current loss=9432.291804305494\n",
      "iter 5, current loss=9432.291804307506\n",
      "iter 6, current loss=9432.29180431777\n",
      "iter 7, current loss=9432.291804291583\n",
      "iter 8, current loss=9432.291804297498\n",
      "iter 9, current loss=9432.291804291583\n",
      "iter 10, current loss=9432.291804305627\n",
      "iter 11, current loss=9432.291804291583\n",
      "iter 12, current loss=9432.291804311184\n",
      "iter 13, current loss=9432.291804291583\n",
      "iter 14, current loss=9432.291804323822\n",
      "iter 15, current loss=9432.291804291583\n",
      "iter 16, current loss=9432.291804274611\n",
      "iter 17, current loss=9436.198480643076\n",
      "iter 18, current loss=9432.291804290351\n",
      "================ STEP 1 ===============\n",
      "19:57-1.7999999999999998\t63.0957344480193\t2.8036903765384254e-7\t0.09432291804289109\t\t4\n",
      "19:57-1.6999999999999997\t50.118723362727195\t2.8036903765384254e-7\t0.11874551843877279\t\t4\n",
      "19:57-1.6999999999999997\t50.118723362727195\t2.8036903765384254e-7\t0.11874551843877279\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=11874.551843878846\n",
      "iter 1, current loss=15738.411721176171\n",
      "iter 2, current loss=11882.70777058445\n",
      "iter 3, current loss=11874.55184385892\n",
      "================ STEP 0 ===============\n",
      "iter 4, current loss=11874.551843861218\n",
      "iter 5, current loss=11874.55184385903\n",
      "iter 6, current loss=11874.551843897358\n",
      "iter 7, current loss=11874.55184387329\n",
      "iter 8, current loss=11874.55184388157\n",
      "iter 9, current loss=11874.55184385892\n",
      "iter 10, current loss=11874.551843878806\n",
      "iter 11, current loss=11874.55184385892\n",
      "iter 12, current loss=11874.551843881121\n",
      "iter 13, current loss=11874.55184385892\n",
      "iter 14, current loss=11874.55184388092\n",
      "iter 15, current loss=11874.55184385892\n",
      "iter 16, current loss=11874.551843849098\n",
      "iter 17, current loss=11874.551843879299\n",
      "iter 18, current loss=11879.736555568312\n",
      "iter 19, current loss=11874.55184387772\n",
      "iter 20, current loss=11874.55184387698\n",
      "iter 21, current loss=11874.551843892923\n",
      "iter 22, current loss=11874.55184388498\n",
      "iter 23, current loss=11874.55184385892\n",
      "iter 24, current loss=11874.551843916577\n",
      "iter 25, current loss=11874.55184385892\n",
      "iter 26, current loss=11874.551843884114\n",
      "iter 27, current loss=11874.55184385892\n",
      "iter 28, current loss=11874.55184388978\n",
      "iter 29, current loss=11874.55184385892\n",
      "iter 30, current loss=11874.551843880354\n",
      "iter 31, current loss=11874.55184385892\n",
      "iter 32, current loss=11874.551843873334\n",
      "19:58-1.6999999999999997\t50.118723362727195\t3.351501526500998e-7\t0.11874551843861436\t\t4\n",
      "19:58-1.5999999999999996\t39.81071705534969\t3.351501526500998e-7\t0.14949175069904314\t\t4\n",
      "19:58-1.5999999999999996\t39.81071705534969\t3.351501526500998e-7\t0.14949175069904314\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=14949.175069901145\n",
      "iter 1, current loss=89388.43110088768\n",
      "iter 2, current loss=14949.175069909672\n",
      "iter 3, current loss=14949.175069942754\n",
      "iter 4, current loss=14949.175069913243\n",
      "iter 5, current loss=14949.175069901954\n",
      "iter 6, current loss=14949.175069901145\n",
      "iter 7, current loss=14949.175069916497\n",
      "iter 8, current loss=14949.175069901145\n",
      "iter 9, current loss=14949.17506990545\n",
      "iter 10, current loss=14949.175069901145\n",
      "iter 11, current loss=14949.175069905918\n",
      "iter 12, current loss=14949.175069901145\n",
      "iter 13, current loss=14949.175069905918\n",
      "iter 14, current loss=14949.175069901145\n",
      "19:58-1.5999999999999996\t39.81071705534969\t3.351501526500998e-7\t0.14949175069904314\t\t4\n",
      "19:58-1.4999999999999996\t31.62277660168376\t3.351501526500998e-7\t0.18819896380862178\t\t4\n",
      "19:58-1.4999999999999996\t31.62277660168376\t3.351501526500998e-7\t0.18819896380862178\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=18819.89638085819\n",
      "iter 1, current loss=104822.28563618608\n",
      "iter 2, current loss=18819.896380865146\n",
      "iter 3, current loss=18819.89638087278\n",
      "iter 4, current loss=18819.896380933766\n",
      "iter 5, current loss=18819.896380861293\n",
      "iter 6, current loss=18819.89638085819\n",
      "iter 7, current loss=18819.896380867023\n",
      "iter 8, current loss=18819.89638085819\n",
      "iter 9, current loss=18819.89638084156\n",
      "iter 10, current loss=18819.896380872437\n",
      "iter 11, current loss=18819.89638084156\n",
      "iter 12, current loss=18819.896380860493\n",
      "iter 13, current loss=18819.89638084156\n",
      "iter 14, current loss=18819.896380860493\n",
      "19:58-1.4999999999999996\t31.62277660168376\t3.351501526500998e-7\t0.18819896380862178\t\t4\n",
      "19:58-1.3999999999999995\t25.11886431509577\t3.351501526500998e-7\t0.2369284580120014\t\t4\n",
      "19:58-1.3999999999999995\t25.11886431509577\t3.351501526500998e-7\t0.2369284580120014\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=23692.845801195126\n",
      "iter 1, current loss=120940.54430751673\n",
      "iter 2, current loss=23692.845801239997\n",
      "iter 3, current loss=23692.845801255648\n",
      "iter 4, current loss=23692.845801234078\n",
      "iter 5, current loss=23692.845801195126\n",
      "iter 6, current loss=23692.84580122133\n",
      "iter 7, current loss=23692.845801195126\n",
      "iter 8, current loss=23692.845801225678\n",
      "iter 9, current loss=23692.845801195126\n",
      "iter 10, current loss=23692.845801244923\n",
      "iter 11, current loss=23692.845801195126\n",
      "iter 12, current loss=23692.845801243486\n",
      "iter 13, current loss=23692.845801195126\n",
      "iter 14, current loss=23692.845801179785\n",
      "19:58-1.3999999999999995\t25.11886431509577\t3.351501526500998e-7\t0.2369284580120014\t\t4\n",
      "19:58-1.2999999999999994\t19.95262314968877\t3.351501526500998e-7\t0.2982752565685107\t\t4\n",
      "19:58-1.2999999999999994\t19.95262314968877\t3.351501526500998e-7\t0.2982752565685107\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=29827.525656844762\n",
      "iter 1, current loss=137287.27255696125\n",
      "iter 2, current loss=29827.525656932645\n",
      "iter 3, current loss=29827.525656923746\n",
      "iter 4, current loss=29827.525656911035\n",
      "iter 5, current loss=29827.525656844762\n",
      "iter 6, current loss=29827.525656866677\n",
      "iter 7, current loss=29827.525656844762\n",
      "iter 8, current loss=29827.525656938407\n",
      "iter 9, current loss=29827.525656844762\n",
      "iter 10, current loss=29827.525656932015\n",
      "iter 11, current loss=29827.525656844762\n",
      "iter 12, current loss=29827.525656878275\n",
      "iter 13, current loss=29827.525656844762\n",
      "iter 14, current loss=29827.525656886308\n",
      "iter 15, current loss=29827.525656844762\n",
      "19:58-1.2999999999999994\t19.95262314968877\t3.351501526500998e-7\t0.2982752565685107\t\t4\n",
      "19:58-1.1999999999999993\t15.84893192461111\t3.351501526500998e-7\t0.37550630020351516\t\t4\n",
      "19:58-1.1999999999999993\t15.84893192461111\t3.351501526500998e-7\t0.37550630020351516\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=37550.63002034356\n",
      "iter 1, current loss=153701.68285145855\n",
      "iter 2, current loss=37550.63002034427\n",
      "iter 3, current loss=37550.630020392346\n",
      "iter 4, current loss=37550.630020394026\n",
      "iter 5, current loss=37550.63002041504\n",
      "iter 6, current loss=37550.63002034356\n",
      "iter 7, current loss=37550.63002042291\n",
      "iter 8, current loss=37550.63002034356\n",
      "iter 9, current loss=37550.63002041386\n",
      "iter 10, current loss=37550.63002034356\n",
      "iter 11, current loss=37550.630020389755\n",
      "iter 12, current loss=37550.63002034356\n",
      "iter 13, current loss=37550.63002045127\n",
      "iter 14, current loss=37550.63002034356\n",
      "iter 15, current loss=37550.63002043688\n",
      "19:59-1.1999999999999993\t15.84893192461111\t3.351501526500998e-7\t0.37550630020351516\t\t4\n",
      "19:59-1.0999999999999992\t12.58925411794165\t3.351501526500998e-7\t0.4727344236150014\t\t4\n",
      "19:59-1.0999999999999992\t12.58925411794165\t3.351501526500998e-7\t0.4727344236150014\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=47273.442361490124\n",
      "iter 1, current loss=170578.56724460446\n",
      "iter 2, current loss=47273.44236150412\n",
      "iter 3, current loss=47273.44236155601\n",
      "iter 4, current loss=47273.44236155109\n",
      "iter 5, current loss=47273.44236163189\n",
      "iter 6, current loss=47273.442361490124\n",
      "iter 7, current loss=47273.44236149241\n",
      "iter 8, current loss=47273.442361490124\n",
      "iter 9, current loss=47273.44236153736\n",
      "iter 10, current loss=47273.442361490124\n",
      "iter 11, current loss=47273.44236149614\n",
      "iter 12, current loss=47273.442361490124\n",
      "iter 13, current loss=47273.442361524496\n",
      "iter 14, current loss=47273.442361490124\n",
      "iter 15, current loss=47273.442361463356\n",
      "19:59-1.0999999999999992\t12.58925411794165\t3.351501526500998e-7\t0.4727344236150014\t\t4\n",
      "19:59-0.9999999999999992\t9.999999999999982\t3.351501526500998e-7\t0.5951373789187732\t\t4\n",
      "19:59-0.9999999999999992\t9.999999999999982\t3.351501526500998e-7\t0.5951373789187732\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=59513.73789186472\n",
      "iter 1, current loss=188937.54259958083\n",
      "iter 2, current loss=59513.73789186813\n",
      "iter 3, current loss=59513.73789202137\n",
      "iter 4, current loss=59513.73789187305\n",
      "iter 5, current loss=59513.73789196809\n",
      "iter 6, current loss=59513.73789186472\n",
      "iter 7, current loss=59513.73789192585\n",
      "iter 8, current loss=59513.73789186472\n",
      "iter 9, current loss=59513.73789194365\n",
      "iter 10, current loss=59513.73789186472\n",
      "iter 11, current loss=59513.73789200814\n",
      "iter 12, current loss=59513.73789186472\n",
      "iter 13, current loss=59513.737891946985\n",
      "iter 14, current loss=59513.73789186472\n",
      "iter 15, current loss=59513.73789193617\n",
      "19:59-0.9999999999999992\t9.999999999999982\t3.351501526500998e-7\t0.5951373789187732\t\t4\n",
      "function for update K:3.351501526500998e-7\t4\n",
      "19:59-0.8999999999999992\t7.943282347242802\t0.0006883561673590331\t0.749237458478965\t\t4\n",
      "19:59-0.8999999999999992\t7.943282347242802\t0.0006883561673590331\t0.749237458478965\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=74923.74584788535\n",
      "iter 1, current loss=208776.59547276553\n",
      "iter 2, current loss=74923.63929402358\n",
      "================ STEP 0 ===============\n",
      "iter 3, current loss=74923.43226008619\n",
      "================ STEP 1 ===============\n",
      "iter 4, current loss=74923.40951630665\n",
      "================ STEP 2 ===============\n",
      "iter 5, current loss=74923.37443330596\n",
      "================ STEP 3 ===============\n",
      "iter 6, current loss=74923.38279079732\n",
      "iter 7, current loss=74923.37025004686\n",
      "================ STEP 4 ===============\n",
      "iter 8, current loss=74923.36776795417\n",
      "================ STEP 5 ===============\n",
      "iter 9, current loss=74923.36291772813\n",
      "================ STEP 6 ===============\n",
      "iter 10, current loss=74923.36071776082\n",
      "================ STEP 7 ===============\n",
      "iter 11, current loss=74923.35905949741\n",
      "================ STEP 8 ===============\n",
      "iter 12, current loss=74923.35854367244\n",
      "================ STEP 9 ===============\n",
      "iter 13, current loss=74923.35819924525\n",
      "================ STEP 10 ===============\n",
      "iter 14, current loss=74923.35796637414\n",
      "================ STEP 11 ===============\n",
      "iter 15, current loss=74923.35783808868\n",
      "================ STEP 12 ===============\n",
      "iter 16, current loss=74923.35776455734\n",
      "================ STEP 13 ===============\n",
      "iter 17, current loss=74923.35769500224\n",
      "================ STEP 14 ===============\n",
      "iter 18, current loss=74923.35768264286\n",
      "================ STEP 15 ===============\n",
      "iter 19, current loss=74923.35763502319\n",
      "================ STEP 16 ===============\n",
      "iter 20, current loss=74923.35760969968\n",
      "================ STEP 17 ===============\n",
      "iter 21, current loss=74923.35757837753\n",
      "================ STEP 18 ===============\n",
      "iter 22, current loss=74923.3575874877\n",
      "iter 23, current loss=74923.35756110045\n",
      "================ STEP 19 ===============\n",
      "iter 24, current loss=74923.35753108386\n",
      "================ STEP 20 ===============\n",
      "iter 25, current loss=74923.35750392573\n",
      "================ STEP 21 ===============\n",
      "iter 26, current loss=74923.35748040321\n",
      "================ STEP 22 ===============\n",
      "iter 27, current loss=74923.35744350057\n",
      "================ STEP 23 ===============\n",
      "iter 28, current loss=74923.35736498093\n",
      "================ STEP 24 ===============\n",
      "iter 29, current loss=74923.35735620909\n",
      "iter 30, current loss=74923.35731025418\n",
      "================ STEP 25 ===============\n",
      "iter 31, current loss=74923.35725273585\n",
      "================ STEP 26 ===============\n",
      "iter 32, current loss=74923.35721240353\n",
      "================ STEP 27 ===============\n",
      "iter 33, current loss=74923.35722372276\n",
      "iter 34, current loss=74923.3571995055\n",
      "================ STEP 28 ===============\n",
      "iter 35, current loss=74923.35718306429\n",
      "================ STEP 29 ===============\n",
      "iter 36, current loss=74923.35713690695\n",
      "================ STEP 30 ===============\n",
      "iter 37, current loss=74923.35711101057\n",
      "================ STEP 31 ===============\n",
      "iter 38, current loss=74923.3570924592\n",
      "================ STEP 32 ===============\n",
      "iter 39, current loss=74923.3570782638\n",
      "================ STEP 33 ===============\n",
      "iter 40, current loss=74923.35707104829\n",
      "================ STEP 34 ===============\n",
      "iter 41, current loss=74923.35706026397\n",
      "================ STEP 35 ===============\n",
      "iter 42, current loss=74923.35704326128\n",
      "================ STEP 36 ===============\n",
      "iter 43, current loss=74923.35703214018\n",
      "================ STEP 37 ===============\n",
      "iter 44, current loss=74923.35702466474\n",
      "================ STEP 38 ===============\n",
      "iter 45, current loss=74923.35702068734\n",
      "================ STEP 39 ===============\n",
      "iter 46, current loss=74923.35701926306\n",
      "================ STEP 40 ===============\n",
      "iter 47, current loss=74923.3570157856\n",
      "================ STEP 41 ===============\n",
      "iter 48, current loss=74923.35701354113\n",
      "================ STEP 42 ===============\n",
      "iter 49, current loss=74923.35701112717\n",
      "================ STEP 43 ===============\n",
      "iter 50, current loss=74923.35700719219\n",
      "================ STEP 44 ===============\n",
      "iter 51, current loss=74923.35700749834\n",
      "iter 52, current loss=74923.35700379807\n",
      "================ STEP 45 ===============\n",
      "iter 53, current loss=74923.35699994894\n",
      "================ STEP 46 ===============\n",
      "iter 54, current loss=74923.35699847082\n",
      "================ STEP 47 ===============\n",
      "iter 55, current loss=74923.35699571265\n",
      "================ STEP 48 ===============\n",
      "iter 56, current loss=74923.35699281671\n",
      "================ STEP 49 ===============\n",
      "iter 57, current loss=74923.35699117083\n",
      "================ STEP 50 ===============\n",
      "iter 58, current loss=74923.35698941028\n",
      "================ STEP 51 ===============\n",
      "iter 59, current loss=74923.35698791652\n",
      "================ STEP 52 ===============\n",
      "iter 60, current loss=74923.35698734317\n",
      "================ STEP 53 ===============\n",
      "iter 61, current loss=74923.35698668858\n",
      "================ STEP 54 ===============\n",
      "iter 62, current loss=74923.35698646892\n",
      "================ STEP 55 ===============\n",
      "iter 63, current loss=74923.35698583888\n",
      "================ STEP 56 ===============\n",
      "iter 64, current loss=74923.35698541574\n",
      "================ STEP 57 ===============\n",
      "iter 65, current loss=74923.35698503396\n",
      "================ STEP 58 ===============\n",
      "iter 66, current loss=74923.35698434617\n",
      "================ STEP 59 ===============\n",
      "iter 67, current loss=74923.35698407603\n",
      "================ STEP 60 ===============\n",
      "iter 68, current loss=74923.35698316296\n",
      "================ STEP 61 ===============\n",
      "iter 69, current loss=74923.35698243884\n",
      "================ STEP 62 ===============\n",
      "iter 70, current loss=74923.35698281297\n",
      "iter 71, current loss=74923.35698199629\n",
      "================ STEP 63 ===============\n",
      "iter 72, current loss=74923.35698141795\n",
      "================ STEP 64 ===============\n",
      "iter 73, current loss=74923.35698121664\n",
      "================ STEP 65 ===============\n",
      "iter 74, current loss=74923.35698115645\n",
      "================ STEP 66 ===============\n",
      "20:00-0.8999999999999992\t7.943282347242802\t1.4745815747778241e-6\t0.7492335698116792\t\t4\n",
      "20:00-0.7999999999999993\t6.309573444801922\t1.4745815747778241e-6\t0.9432291804050507\t\t4\n",
      "20:00-0.7999999999999993\t6.309573444801922\t1.4745815747778241e-6\t0.9432291804050507\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=94322.91804049067\n",
      "iter 1, current loss=228121.38505532517\n",
      "iter 2, current loss=94322.91804002912\n",
      "================ STEP 0 ===============\n",
      "iter 3, current loss=94322.91804001592\n",
      "================ STEP 1 ===============\n",
      "20:00-0.7999999999999993\t6.309573444801922\t9.372576277501346e-7\t0.9432291804003035\t\t4\n",
      "20:00-0.6999999999999993\t5.011872336272715\t9.372576277501346e-7\t1.187455184351549\t\t4\n",
      "20:00-0.6999999999999993\t5.011872336272715\t9.372576277501346e-7\t1.187455184351549\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=118745.51843513675\n",
      "iter 1, current loss=269970.2463534177\n",
      "iter 2, current loss=118745.51843515535\n",
      "iter 3, current loss=118745.51843534155\n",
      "iter 4, current loss=118745.51843527936\n",
      "iter 5, current loss=118745.51843519555\n",
      "iter 6, current loss=118745.51843513675\n",
      "iter 7, current loss=118745.51843545443\n",
      "iter 8, current loss=118745.51843513675\n",
      "iter 9, current loss=118745.51843541746\n",
      "iter 10, current loss=118745.51843513675\n",
      "iter 11, current loss=118745.51843510414\n",
      "iter 12, current loss=118745.51843532817\n",
      "iter 13, current loss=118745.51843510414\n",
      "iter 14, current loss=118745.51843519649\n",
      "20:01-0.6999999999999993\t5.011872336272715\t9.372576277501346e-7\t1.187455184351549\t\t4\n",
      "20:01-0.5999999999999993\t3.981071705534966\t9.372576277501346e-7\t1.494917506946611\t\t4\n",
      "20:01-0.5999999999999993\t3.981071705534966\t9.372576277501346e-7\t1.494917506946611\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=149491.75069463823\n",
      "iter 1, current loss=322786.23713722907\n",
      "iter 2, current loss=149491.75069477124\n",
      "iter 3, current loss=149491.7506947611\n",
      "iter 4, current loss=149491.75069465055\n",
      "iter 5, current loss=149491.75069476126\n",
      "iter 6, current loss=149491.75069463823\n",
      "iter 7, current loss=149491.75069490797\n",
      "iter 8, current loss=149491.75069463823\n",
      "iter 9, current loss=149491.750695019\n",
      "iter 10, current loss=149491.75069463823\n",
      "iter 11, current loss=149491.75069466233\n",
      "iter 12, current loss=149491.75069463823\n",
      "iter 13, current loss=149491.750694552\n",
      "iter 14, current loss=149491.75069487942\n",
      "20:01-0.5999999999999993\t3.981071705534966\t9.372576277501346e-7\t1.494917506946611\t\t4\n",
      "20:01-0.49999999999999933\t3.1622776601683746\t9.372576277501346e-7\t1.8819896380306254\t\t4\n",
      "20:01-0.49999999999999933\t3.1622776601683746\t9.372576277501346e-7\t1.8819896380306254\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=188198.96380303375\n",
      "iter 1, current loss=378384.6463169609\n",
      "iter 2, current loss=188198.96380303512\n",
      "iter 3, current loss=188198.96380304103\n",
      "iter 4, current loss=188198.96380323495\n",
      "iter 5, current loss=188198.9638031045\n",
      "iter 6, current loss=188198.96380321824\n",
      "iter 7, current loss=188198.96380303375\n",
      "iter 8, current loss=188198.96380350037\n",
      "iter 9, current loss=188198.96380303375\n",
      "iter 10, current loss=188198.96380300945\n",
      "iter 11, current loss=188198.96380326952\n",
      "iter 12, current loss=188198.96380300945\n",
      "iter 13, current loss=188198.9638031571\n",
      "iter 14, current loss=188198.96380300945\n",
      "20:01-0.49999999999999933\t3.1622776601683746\t9.372576277501346e-7\t1.8819896380306254\t\t4\n",
      "20:01-0.39999999999999936\t2.5118864315095766\t9.372576277501346e-7\t2.3692845800493525\t\t4\n",
      "20:01-0.39999999999999936\t2.5118864315095766\t9.372576277501346e-7\t2.3692845800493525\t\t4\n",
      "C:\\Users\\dbeli\\.julia\\adcme\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME C:\\Users\\dbeli\\.julia\\packages\\ADCME\\cupNK\\src\\optim.jl:332\n",
      "iter 0, current loss=236928.45800489903\n",
      "iter 1, current loss=429960.7904009963\n",
      "iter 2, current loss=236928.45800443838\n",
      "================ STEP 0 ===============\n",
      "iter 3, current loss=236928.45800442307\n",
      "================ STEP 1 ===============\n",
      "20:01-0.39999999999999936\t2.5118864315095766\t5.645814969352102e-7\t2.3692845800447877\t\t4\n",
      "20:01-0.2999999999999994\t1.9952623149688768\t5.645814969352102e-7\t2.982752565586553\t\t4\n"
     ]
    }
   ],
   "source": [
    "T_exp_final =4\n",
    "\n",
    "while T_exp <= T_exp_final\n",
    "\n",
    "    global T_=  10.0 ^ (-T_exp) \n",
    "\n",
    "    print_status(sess,loss,diff_eval,T_exp,T_,N_k_dis_,tf_variables)\n",
    "    check_diff_ = run(sess,diff_eval,feed_dict = Dict(tf_variables.lambda => ones(1)*T_,tf_variables.N_k_dis=>N_k_dis_))  \n",
    "    print_status(sess,loss,diff_eval,T_exp,T_,N_k_dis_,tf_variables)\n",
    "    # ScipyOptimizerMinimize(sess, opt_LFGS,feed_dict = Dict(tf_variables.lambda => ones(1)*T_,tf_variables.N_k_dis=>N_k_dis_))\n",
    "    BFGS!(sess,loss*1e5,options=Dict(\"maxiter\"=> 100, \"ftol\"=>1e-12, \"gtol\"=>1e-12),feed_dict = Dict(tf_variables.lambda => ones(1)*T_,tf_variables.N_k_dis=>N_k_dis_))\n",
    "\n",
    "    print_status(sess,loss,diff_eval,T_exp,T_,N_k_dis_,tf_variables)\n",
    "    if round(T_exp,digits=2)%1 == 0\n",
    "\n",
    "        # save_values(sess,param_model_val,tf_variables,q_t_x, q_t_y,p)\n",
    "        check_diff_ = run(sess,diff_eval,feed_dict = Dict(tf_variables.lambda => ones(1)*T_,tf_variables.N_k_dis=>N_k_dis_))  \n",
    "        global N_k_dis_ = update_K_p(sess,param_model_val,tf_variables,check_diff_,N_k_dis_,p_pre_soft_max)\n",
    "\n",
    "    end\n",
    "\n",
    "    global T_exp += 0.1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}